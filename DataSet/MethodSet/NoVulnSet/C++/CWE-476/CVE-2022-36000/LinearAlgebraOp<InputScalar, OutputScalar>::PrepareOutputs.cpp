void LinearAlgebraOp<InputScalar, OutputScalar>::PrepareOutputs(
    OpKernelContext* context, const TensorShapes& input_matrix_shapes,
    const TensorShape& batch_shape, TensorOutputs* outputs,
    TensorShapes* output_matrix_shapes) {
  // Get shape for each of the matrix outputs produced by the derived class.
  *output_matrix_shapes = GetOutputMatrixShapes(input_matrix_shapes);
  const int num_outputs = output_matrix_shapes->size();

  // Make sure the number of op outputs is what the derived class expects.
  OP_REQUIRES(
      context, num_outputs <= context->num_outputs(),
      errors::Internal(
          "Derived class expected more outputs (%d) that the op has (%d).",
          num_outputs, context->num_outputs()));

  // Allocate outputs.
  std::set<int> unused_inputs;
  for (int input_idx = 0; input_idx < context->num_inputs(); ++input_idx) {
    unused_inputs.insert(input_idx);
  }
  for (int output_idx = 0; output_idx < context->num_outputs(); ++output_idx) {
    TensorShape output_tensor_shape({});
    if (output_idx < num_outputs) {
      // This output is used, set up output shape and allocate it.
      const TensorShape& output_matrix_shape =
          output_matrix_shapes->at(output_idx);
      OP_REQUIRES(context, output_matrix_shape.dims() <= 2,
                  errors::InvalidArgument(
                      "Rank of matrix output no. %d must be 0, 1 or 2, got %d.",
                      output_idx, output_matrix_shape.dims()));

      // The final output has the shape of the outer batch dimensions
      // concatenated with the output_matrix_shape (if the output is not
      // scalar).
      output_tensor_shape = batch_shape;
      output_tensor_shape.AppendShape(output_matrix_shape);
    }
    Tensor* out = nullptr;
    // See if there is an input buffer we can reuse for this output.
    bool reused_input = false;
    if (EnableInputForwarding()) {
      for (int input_idx : unused_inputs) {
        if (context->forward_input_to_output_with_shape(
                input_idx, output_idx, output_tensor_shape, &out)) {
          reused_input = true;
          unused_inputs.erase(input_idx);
          break;
        }
      }
    }
    if (!reused_input) {
      OP_REQUIRES_OK(context, context->allocate_output(
                                  output_idx, output_tensor_shape, &out));
    }
    OP_REQUIRES(
        context, out->dtype() == DataTypeToEnum<OutputScalar>::v(),
        errors::InvalidArgument("Invalid output dtype ", out->dtype(), " vs ",
                                DataTypeToEnum<OutputScalar>::v()));

    outputs->emplace_back(out);
  }
}