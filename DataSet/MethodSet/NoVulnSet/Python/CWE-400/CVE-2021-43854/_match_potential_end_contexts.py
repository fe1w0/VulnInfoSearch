'\n        Given a text, find the matches of potential sentence breaks,\n        alongside the contexts surrounding these sentence breaks.\n\n        Since the fix for the ReDOS discovered in issue #2866, we no longer match\n        the word before a potential end of sentence token. Instead, we use a separate\n        regex for this. As a consequence, `finditer`\'s desire to find non-overlapping\n        matches no longer aids us in finding the single longest match.\n        Where previously, we could use::\n\n            >>> pst = PunktSentenceTokenizer()\n            >>> text = "Very bad acting!!! I promise."\n            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\n            [<re.Match object; span=(9, 18), match=\'acting!!!\'>]\n\n        Now we have to find the word before (i.e. \'acting\') separately, and `finditer`\n        returns::\n\n            >>> pst = PunktSentenceTokenizer()\n            >>> text = "Very bad acting!!! I promise."\n            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\n            [<re.Match object; span=(15, 16), match=\'!\'>,\n            <re.Match object; span=(16, 17), match=\'!\'>,\n            <re.Match object; span=(17, 18), match=\'!\'>]\n\n        So, we need to find the word before the match from right to left, and then manually remove\n        the overlaps. That is what this method does::\n\n            >>> pst = PunktSentenceTokenizer()\n            >>> text = "Very bad acting!!! I promise."\n            >>> pst._match_potential_end_contexts(text)\n            [(<re.Match object; span=(17, 18), match=\'!\'>, \'acting!!! I\')]\n\n        :param text: String of one or more sentences\n        :type text: str\n        :return: List of match-context tuples.\n        :rtype: List[Tuple[re.Match, str]]\n        '
before_words = {}
matches = []
for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):
    if matches and match.end() > before_start:
        continue
    split = text[:match.start()].rsplit(maxsplit=1)
    before_start = len(split[0]) if len(split) == 2 else 0
    before_words[match] = split[-1]
    matches.append(match)
return [(match, before_words[match] + match.group() + match.group('after_tok')) for match in matches[::-1]]