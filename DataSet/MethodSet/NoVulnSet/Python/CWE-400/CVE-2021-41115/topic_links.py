def topic_links(linkifiers_key: int, topic_name: str) -> List[Dict[str, str]]:
    matches: List[Dict[str, Union[str, int]]] = []
    linkifiers = linkifiers_for_realm(linkifiers_key)
    options = re2.Options()
    options.log_errors = False
    for linkifier in linkifiers:
        raw_pattern = linkifier['pattern']
        url_format_string = linkifier['url_format']
        try:
            pattern = re2.compile(prepare_linkifier_pattern(raw_pattern), options=options)
        except re2.error:
            continue
        for m in pattern.finditer(topic_name):
            match_details = m.groupdict()
            match_text = match_details['linkifier_actual_match']
            matches += [dict(url=url_format_string % match_details, text=match_text, index=topic_name.find(match_text))]
    for sub_string in basic_link_splitter.split(topic_name):
        link_match = re.match(get_web_link_regex(), sub_string)
        if link_match:
            actual_match_url = link_match.group('url')
            result = urlsplit(actual_match_url)
            if not result.scheme:
                if not result.netloc:
                    i = (result.path + '/').index('/')
                    result = result._replace(netloc=result.path[:i], path=result.path[i:])
                url = result._replace(scheme='https').geturl()
            else:
                url = actual_match_url
            matches.append(dict(url=url, text=actual_match_url, index=topic_name.find(actual_match_url)))
    matches = sorted(matches, key=lambda k: k['index'])
    return [{k: str(v) for (k, v) in match.items() if k != 'index'} for match in matches]