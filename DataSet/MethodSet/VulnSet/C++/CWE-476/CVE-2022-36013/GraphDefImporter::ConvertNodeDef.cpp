Status GraphDefImporter::ConvertNodeDef(OpBuilder &builder, ConversionState &s,
                                        const NodeDef &node) {
  VLOG(4) << "Importing: " << node.name();
  OperationState state(ConvertLocation(node), absl::StrCat("tfg.", node.op()));

  // The GraphImporter does light shape inference, but here we will defer all of
  // that to the shape inference pass.
  const OpDef *op_def;
  const OpRegistrationData *op_reg_data = nullptr;
  if ((op_reg_data = registry_.LookUp(node.op()))) {
    op_def = &op_reg_data->op_def;
  } else {
    auto it = function_op_defs_.find(node.op());
    if (it == function_op_defs_.end())
      return InvalidArgument("Unable to find OpDef for ", node.op());
    op_def = it->second;
  }

  // Import the attributes. Reserve `+3` for `device`,`name`, and `fulltype`.
  state.attributes.reserve(node.attr_size() + 3);
  if (!node.device().empty()) {
    state.addAttribute(dialect_->getDeviceAttrIdentifier(),
                       b_.getStringAttr(node.device()));
  }
  if (!node.name().empty()) {
    state.addAttribute(dialect_->getNameAttrIdentifier(),
                       b_.getStringAttr(node.name()));
  }

  // If the op doesn't have a FullType, try to infer one.
  const auto add_full_type = [&](const FullTypeDef &full_type_def) {
    TF_ASSIGN_OR_RETURN(tf_type::FullTypeAttr full_type,
                        ConvertAttribute(full_type_def, b_, dialect_));
    state.addAttribute(dialect_->getFullTypeAttrIdentifier(), full_type);
    return ::tensorflow::OkStatus();
  };
  if (node.has_experimental_type()) {
    TF_RETURN_IF_ERROR(add_full_type(node.experimental_type()));
  } else if (op_reg_data && op_reg_data->type_ctor) {
    FullTypeDef full_type_def;
    TF_RETURN_IF_ERROR(
        tensorflow::full_type::SpecializeType(node, *op_def, full_type_def));
    TF_RETURN_IF_ERROR(add_full_type(full_type_def));
  }

  for (auto &name_attr : node.attr()) {
    if (name_attr.first.empty())
      return InvalidArgument("Node ", node.name(), " has an empty attr name");
    TF_ASSIGN_OR_RETURN(Attribute attr,
                        ConvertAttributeValue(name_attr.second, b_, dialect_));
    state.addAttribute(name_attr.first, attr);
  }

  // Add missing default attributes.
  for (const auto &attr_def : op_def->attr()) {
    if (attr_def.has_default_value() &&
        !state.attributes.get(attr_def.name())) {
      TF_ASSIGN_OR_RETURN(
          Attribute attr,
          ConvertAttributeValue(attr_def.default_value(), b_, dialect_));
      state.addAttribute(attr_def.name(), attr);
    }
  }

  // Get the result types. Ops can have multiple named results. Track the
  // segment sizes.
  SmallVector<std::pair<unsigned, unsigned>> result_segments;
  result_segments.reserve(op_def->output_arg_size());
  state.types.reserve(op_def->output_arg_size() + 1);
  for (const OpDef::ArgDef &def : op_def->output_arg()) {
    unsigned index = state.types.size();
    TF_ASSIGN_OR_RETURN(unsigned size,
                        ArgNumType(state.attributes, def, state.types));
    result_segments.emplace_back(index, size);
  }
  state.types.push_back(dialect_->getControlType());

  // Collect the operands. Set backedges to a placeholder and resolve them
  // later.
  state.operands.reserve(node.input_size());
  SmallVector<Value> control_operands;
  struct BackedgeResolution {
    ResultInfo *info;
    size_t operand_index;
    ResultId id;
  };
  SmallVector<BackedgeResolution> unresolved_data_operands,
      unresolved_control_operands;
  for (const std::string &input : node.input()) {
    TF_ASSIGN_OR_RETURN(Result result, GetResult(s, input));
    if (result.control) {
      if (result.info) {
        unresolved_control_operands.push_back(BackedgeResolution{
            result.info, control_operands.size(), result.id});
      }
      control_operands.push_back(result.control);
    } else {
      if (result.info) {
        unresolved_data_operands.push_back(
            BackedgeResolution{result.info, state.operands.size(), result.id});
      }
      state.operands.push_back(result.data);
    }
  }
  unsigned num_data_operands = state.operands.size();
  state.addOperands(control_operands);

  // Create the op and record any unresolved operands.
  Operation *op = builder.create(state);
  for (const BackedgeResolution &r : unresolved_data_operands) {
    r.info->backedges.push_back(
        Backedge{r.id, &op->getOpOperand(r.operand_index)});
  }
  for (const BackedgeResolution &r : unresolved_control_operands) {
    r.info->backedges.push_back(
        Backedge{r.id, &op->getOpOperand(num_data_operands + r.operand_index)});
  }

  std::unique_ptr<ResultInfo> &info = s[node.name()];
  if (!info) {
    info = std::make_unique<ResultInfo>();
  }
  info->resolved = true;
  info->control = *std::prev(op->result_end());
  info->data = op->getResults().drop_back();
  for (auto it : llvm::zip(result_segments, op_def->output_arg())) {
    const std::pair<unsigned, unsigned> &segment = std::get<0>(it);
    info->outputs.emplace(std::get<1>(it).name(),
                          info->data.slice(segment.first, segment.second));
  }

  // Resolve any associated backedges.
  for (const Backedge &backedge : info->backedges) {
    Value value;
    if (backedge.id.IsControl()) {
      value = info->control;
    } else {
      TF_ASSIGN_OR_RETURN(value, ResolveDataResult(backedge.id, info.get()));
    }
    backedge.operand->set(value);
  }
  info->backedges.clear();

  return ::tensorflow::OkStatus();
}